{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4cbad65-d59e-4437-8243-9a6dcc53fd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一页的学校名称有：['麻省理工学院', '剑桥大学', '牛津大学', '哈佛大学', '斯坦福大学', '帝国理工学院', '苏黎世联邦理工大学（瑞士联邦理工学院）', '新加坡国立大学', '伦敦大学学院', '加州大学伯克利分校', '芝加哥大学', '宾夕法尼亚大学', '康奈尔大学', '墨尔本大学', '加州理工大学（Caltech)', '耶鲁大学', '北京大学', '普林斯顿大学', '新南威尔士大学（UNSW）', '悉尼大学', '多伦多大学', '爱丁堡大学', '哥伦比亚大学', '巴黎科学艺术人文大学', '清华大学']\n",
      "第一页的学校排名有：['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '=17', '=17', '=19', '=19', '21', '22', '23', '24', '25']\n",
      "前 2 页的学校排名有：['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '=17', '=17', '=19', '=19', '21', '22', '23', '24', '25', '=26', '=26', '28', '28', '29', '30', '32', '33', '=34', '=34', '36', '37', '=38', '=38', '40', '41', '42', '43', '=44', '45', '46', '=47', '=47', '=47', '50']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 定义 ChromeDriver 路径\n",
    "CHROME_DRIVER_PATH = r'C:\\Users\\19521\\Desktop\\chromedriver-win64\\chromedriver.exe'\n",
    "# 定义目标网页 URL\n",
    "URL = \"https://www.qschina.cn/university-rankings/world-university-rankings/2024\"\n",
    "# 定义要爬取的页数\n",
    "PAGES_TO_SCRAPE = 40\n",
    "# 定义保存文件夹路径（可根据需要修改）\n",
    "SAVE_FOLDER = r\"C:\\Users\\19521\\Desktop\\我的论文\\代码\"\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"\n",
    "    初始化 Chrome 浏览器驱动\n",
    "    :return: 浏览器驱动实例\n",
    "    \"\"\"\n",
    "    service = Service(executable_path=CHROME_DRIVER_PATH)\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    return driver\n",
    "\n",
    "def click_element(driver, xpath):\n",
    "    \"\"\"\n",
    "    点击指定 XPath 的元素，使用显式等待确保元素可点击\n",
    "    :param driver: 浏览器驱动实例\n",
    "    :param xpath: 元素的 XPath\n",
    "    \"\"\"\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, xpath))\n",
    "        )\n",
    "        element.click()\n",
    "    except Exception as e:\n",
    "        print(f\"点击元素时出现错误: {e}\")\n",
    "\n",
    "def scroll_page(driver, scroll_distance):\n",
    "    \"\"\"\n",
    "    滚动网页到指定距离\n",
    "    :param driver: 浏览器驱动实例\n",
    "    :param scroll_distance: 滚动的距离\n",
    "    \"\"\"\n",
    "    driver.execute_script(f\"document.documentElement.scrollTop={scroll_distance}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "def get_text(driver, data_lists):\n",
    "    \"\"\"\n",
    "    从当前页面提取所需数据并存储到相应列表中\n",
    "    :param driver: 浏览器驱动实例\n",
    "    :param data_lists: 存储数据的列表集合\n",
    "    \"\"\"\n",
    "    rank_all, name_all, href_all, location_all, score_all, academic_all, repu_all, \\\n",
    "    ts_all, citation_all, internationT_all, internationS_all, research_all, \\\n",
    "    employment_all, sustain_all = data_lists\n",
    "\n",
    "    # rank 排名\n",
    "    list_rank = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" rank\"]')\n",
    "    for li_rank in list_rank:\n",
    "        try:\n",
    "            rank = li_rank.get_attribute('innerHTML').split('td-wrap-in\">')[1].split('</div>')[0]\n",
    "            rank_all.append(rank)\n",
    "        except IndexError:\n",
    "            rank_all.append(np.nan)\n",
    "\n",
    "    # name 大学名称\n",
    "    list_name = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" uni\"]/div/div')\n",
    "    for li_name in list_name:\n",
    "        try:\n",
    "            name = li_name.find_element(By.XPATH, './a').text\n",
    "            name_all.append(name)\n",
    "        except Exception:\n",
    "            name_all.append(np.nan)\n",
    "\n",
    "    # href 大学详情链接地址\n",
    "    list_href = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" uni\"]/div/div')\n",
    "    for li_href in list_href:\n",
    "        try:\n",
    "            href = li_href.find_element(By.XPATH, './a').get_attribute('href')\n",
    "            href_all.append(href)\n",
    "        except Exception:\n",
    "            href_all.append(np.nan)\n",
    "\n",
    "    # location 大学所处国家\n",
    "    list_location = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" uni\"]/div/div/div')\n",
    "    for li_location in list_location:\n",
    "        location = li_location.text\n",
    "        location_all.append(location)\n",
    "\n",
    "    # 综合得分\n",
    "    list_score = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\"ind-col ind-overall sorting_1\"]')\n",
    "    for li_score in list_score:\n",
    "        score = li_score.text\n",
    "        score_all.append(score)\n",
    "\n",
    "    # 学术声誉\n",
    "    list_academic = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" ind-col ind-76\"]')\n",
    "    for li_academic in list_academic:\n",
    "        try:\n",
    "            academic = li_academic.find_element(By.XPATH, './div/div').text\n",
    "            academic_all.append(academic)\n",
    "        except Exception:\n",
    "            academic_all.append(np.nan)\n",
    "\n",
    "    # 雇主声誉\n",
    "    list_repu = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" ind-col ind-77\"]')\n",
    "    for li_repu in list_repu:\n",
    "        try:\n",
    "            repu = li_repu.find_element(By.XPATH, './div/div').text\n",
    "            repu_all.append(repu)\n",
    "        except Exception:\n",
    "            repu_all.append(np.nan)\n",
    "\n",
    "    # 每位教员引用率\n",
    "    list_citation = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" ind-col ind-73\"]')\n",
    "    for li_citation in list_citation:\n",
    "        try:\n",
    "            citation = li_citation.find_element(By.XPATH, './div/div').text\n",
    "            citation_all.append(citation)\n",
    "        except Exception:\n",
    "            citation_all.append(np.nan)\n",
    "\n",
    "    # 师生比\n",
    "    list_ts = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" ind-col ind-36\"]')\n",
    "    for li_ts in list_ts:\n",
    "        try:\n",
    "            ts = li_ts.find_element(By.XPATH, './div/div').text\n",
    "            ts_all.append(ts)\n",
    "        except Exception:\n",
    "            ts_all.append(np.nan)\n",
    "\n",
    "    # 国际学生占比\n",
    "    list_internationS = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" ind-col ind-14\"]')\n",
    "    for li_internationS in list_internationS:\n",
    "        try:\n",
    "            internationS = li_internationS.find_element(By.XPATH, './div/div').text\n",
    "            internationS_all.append(internationS)\n",
    "        except Exception:\n",
    "            internationS_all.append(np.nan)\n",
    "\n",
    "    # 国际教师占比\n",
    "    list_internationT = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" ind-col ind-18\"]')\n",
    "    for li_internationT in list_internationT:\n",
    "        try:\n",
    "            internationT = li_internationT.find_element(By.XPATH, './div/div').text\n",
    "            internationT_all.append(internationT)\n",
    "        except Exception:\n",
    "            internationT_all.append(np.nan)\n",
    "\n",
    "    # 国际研究网络\n",
    "    list_research = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" ind-col ind-15\"]')\n",
    "    for li_research in list_research:\n",
    "        try:\n",
    "            research = li_research.find_element(By.XPATH, './div/div').text\n",
    "            research_all.append(research)\n",
    "        except Exception:\n",
    "            research_all.append(np.nan)\n",
    "\n",
    "    # 就业结果\n",
    "    list_employment = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" ind-col ind-2177844\"]')\n",
    "    for li_employment in list_employment:\n",
    "        try:\n",
    "            employment = li_employment.find_element(By.XPATH, './div/div').text\n",
    "            employment_all.append(employment)\n",
    "        except Exception:\n",
    "            employment_all.append(np.nan)\n",
    "\n",
    "    # 可持续性\n",
    "    list_sustain = driver.find_elements(By.XPATH, '//*[@id=\"qs-rankings-indicators\"]/tbody/tr//td[@class=\" ind-col ind-2208745\"]')\n",
    "    for li_sustain in list_sustain:\n",
    "        try:\n",
    "            sustain = li_sustain.find_element(By.XPATH, './div/div').text\n",
    "            sustain_all.append(sustain)\n",
    "        except Exception:\n",
    "            sustain_all.append(np.nan)\n",
    "\n",
    "    return [rank_all, name_all, href_all, location_all, score_all, academic_all, repu_all,\n",
    "            ts_all, citation_all, internationT_all, internationS_all, research_all,\n",
    "            employment_all, sustain_all]\n",
    "\n",
    "def clean_location(location_all):\n",
    "    \"\"\"\n",
    "    清理 location_all 列表中的无效数据\n",
    "    :param location_all: 存储大学所处国家的列表\n",
    "    :return: 清理后的列表\n",
    "    \"\"\"\n",
    "    invalid_values = ['5+ QS Stars', '5 QS Stars', '4 QS Stars', '3 QS Stars', '']\n",
    "    return [loc for loc in location_all if loc not in invalid_values]\n",
    "\n",
    "def clean_rank(value):\n",
    "    \"\"\"\n",
    "    清理排名数据，将字符串转换为数值\n",
    "    :param value: 排名数据\n",
    "    :return: 清理后的数值\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            if value.startswith('='):\n",
    "                return int(value[1:])\n",
    "            elif '-' in value:\n",
    "                start, end = map(int, value.split('-'))\n",
    "                return (start + end) // 2\n",
    "            else:\n",
    "                return int(value)\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def main():\n",
    "    driver = setup_driver()\n",
    "    driver.get(URL)\n",
    "\n",
    "    # 点击指定元素\n",
    "    click_element(driver, '//*[@id=\"qs-rankings-datatables\"]/div[1]/ul/li[2]/a')\n",
    "\n",
    "    # 初始化数据列表，改为列表类型\n",
    "    data_lists = [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "\n",
    "    # 爬取第一页数据\n",
    "    data_lists = get_text(driver, data_lists)\n",
    "    print(f'第一页的学校名称有：{data_lists[1]}')\n",
    "    print(f'第一页的学校排名有：{data_lists[0]}')\n",
    "\n",
    "    # 滚动页面并点击下一页\n",
    "    scroll_page(driver, 2500)\n",
    "    click_element(driver, '//*[@id=\"qs-rankings-indicators_next\"]')\n",
    "    data_lists = get_text(driver, data_lists)\n",
    "    print(f'前 2 页的学校排名有：{data_lists[0]}')\n",
    "\n",
    "    # 循环爬取剩余页面\n",
    "    for _ in range(2, PAGES_TO_SCRAPE):\n",
    "        scroll_page(driver, 2100)\n",
    "        click_element(driver, '//*[@id=\"qs-rankings-indicators_next\"]')\n",
    "        data_lists = get_text(driver, data_lists)\n",
    "\n",
    "    # 清理 location 数据\n",
    "    data_lists[3] = clean_location(data_lists[3])\n",
    "\n",
    "    # 创建 DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        '排名': data_lists[0],\n",
    "        '大学名称': data_lists[1],\n",
    "        '详情链接': data_lists[2],\n",
    "        '所处国家': data_lists[3],\n",
    "        '综合得分': data_lists[4],\n",
    "        '学术声誉': data_lists[5],\n",
    "        '雇主声誉': data_lists[6],\n",
    "        '师生比': data_lists[7],\n",
    "        '每位教员引用率': data_lists[8],\n",
    "        '国际教师占比': data_lists[9],\n",
    "        '国际学生占比': data_lists[10],\n",
    "        '国际研究网络': data_lists[11],\n",
    "        '就业结果': data_lists[12],\n",
    "        '可持续性': data_lists[13]\n",
    "    })\n",
    "\n",
    "    # 清理排名数据\n",
    "    df['排名'] = df['排名'].apply(clean_rank)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # 确保保存文件夹存在，如果不存在则创建\n",
    "    if not os.path.exists(SAVE_FOLDER):\n",
    "        os.makedirs(SAVE_FOLDER)\n",
    "\n",
    "    # 拼接完整的文件路径\n",
    "    file_path = os.path.join(SAVE_FOLDER, \"qs_ranking.xlsx\")\n",
    "\n",
    "    # 将数据保存到指定路径\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "    # 关闭浏览器\n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c4553b7-f315-4fe8-b4eb-06ccd4b997df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 假设已经读取并处理好数据，存储在 df 中\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 选择用于聚类分析的特征列\u001b[39;00m\n\u001b[0;32m      6\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m综合得分\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m学术声誉\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m雇主声誉\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m师生比\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m每位教员引用率\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      7\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m国际教师占比\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m国际学生占比\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m国际研究网络\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m就业结果\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m可持续性\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m X \u001b[38;5;241m=\u001b[39m df[features]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 数据标准化，因为不同特征的量纲可能不同\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设已经读取并处理好数据，存储在 df 中\n",
    "# 选择用于聚类分析的特征列\n",
    "features = ['综合得分', '学术声誉', '雇主声誉', '师生比', '每位教员引用率', \n",
    "            '国际教师占比', '国际学生占比', '国际研究网络', '就业结果', '可持续性']\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "# 数据标准化，因为不同特征的量纲可能不同\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03958f66-24ca-4935-b9f1-4cc7faf7aee5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_range:\n\u001b[0;32m      8\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mk, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     kmeans\u001b[38;5;241m.\u001b[39mfit(X_scaled)\n\u001b[0;32m     10\u001b[0m     inertia\u001b[38;5;241m.\u001b[39mappend(kmeans\u001b[38;5;241m.\u001b[39minertia_)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 绘制肘部图\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 尝试不同的 k 值\n",
    "inertia = []\n",
    "k_range = range(1, 11)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# 绘制肘部图\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72047e2-39ec-4143-92ee-bfcb8afe15b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
